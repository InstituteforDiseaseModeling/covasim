{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# T7 - Calibration\n",
    "\n",
    "We saw in Tutorial 4 how to load and plot data. But the next step is to actually *calibrate* the model to the data, i.e. find the model parameters that are the most likely explanation for the observed data. This tutorial gives an introduction to the Fit object and some recipes for optimization approaches.\n",
    "\n",
    "## The Fit object\n",
    "\n",
    "The Fit object is responsible for quantifying how well a given model run matches the data. Let's consider a simple example, building on Tutorial 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import covasim as cv\n",
    "cv.options.set(dpi=100, show=False, close=True, verbose=0) # Standard options for Jupyter notebook\n",
    "\n",
    "pars = dict(\n",
    "    pop_size = 10_000,\n",
    "    start_day = '2020-02-01',\n",
    "    end_day   = '2020-04-11',\n",
    "    beta      = 0.015,\n",
    ")\n",
    "sim = cv.Sim(pars=pars, datafile='example_data.csv', interventions=cv.test_num(daily_tests='data'))\n",
    "sim.run()\n",
    "sim.plot(to_plot=['cum_tests', 'cum_diagnoses', 'cum_deaths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that tests match extremely well (they're input data!), diagnoses match reasonably well, and deaths match poorly. Can the Fit object capture our intuition about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sim.compute_fit()\n",
    "print(fit.mismatches)\n",
    "print(fit.mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results seem to match our intuition. (Note that by default the Fit object uses normalized absolute difference, but other estimates, such as mean squared error, are also possible.)\n",
    "\n",
    "What if we improve the fit? Does the mismatch reduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim['rel_death_prob'] = 2 # Double the death rate since deaths were too low\n",
    "sim.initialize(reset=True) # Reinitialize the sim\n",
    "\n",
    "# Rerun and compute fit\n",
    "sim.run()\n",
    "fit = sim.compute_fit()\n",
    "\n",
    "# Output\n",
    "sim.plot()\n",
    "fit.plot()\n",
    "print(fit.mismatches)\n",
    "print(fit.mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the fit is improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration approaches\n",
    "\n",
    "Calibration is a complex and dark art and cannot be covered fully here; many books have been written about it and it continues to be an area of active research. A good review article about calibrating agent-based models like Covasim is available [here](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007893). Calibration is usually expressed as an optimization problem: specifically, find a vector of parameters *θ* that minimizes the mismatch between the data *D* and the model *M(θ)*.\n",
    "\n",
    "In practice, most calibration is done simply by hand, as in the example above. Once deaths are \"calibrated\", the user might modify testing assumptions so that the diagnoses match. Since we are only fitting to deaths and diagnoses, the model is then \"calibrated\".\n",
    "\n",
    "However, automated approaches to calibration are possible as well. The simplest is probably the built-in SciPy optimization functions, e.g. `scipy.optimize`. A wrinkle here is that normal gradient descent methods **will not work** with Covasim or other agent-based models, due to the stochastic variability between model runs that makes the landscape very \"bumpy\". One way of getting around this is to use many different runs and take the average, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import covasim as cv\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def objective(x, n_runs=10):\n",
    "    print(f'Running sim for beta={x[0]}, rel_death_prob={x[1]}')\n",
    "    pars = dict(\n",
    "        pop_size       = 10_000,\n",
    "        start_day      = '2020-02-01',\n",
    "        end_day        = '2020-04-11',\n",
    "        beta           = x[0],\n",
    "        rel_death_prob = x[1],\n",
    "        verbose        = 0,\n",
    "    )\n",
    "    sim = cv.Sim(pars=pars, datafile='/home/cliffk/idm/covasim/docs/tutorials/example_data.csv', interventions=cv.test_num(daily_tests='data'))\n",
    "    msim = cv.MultiSim(sim)\n",
    "    msim.run(n_runs=n_runs)\n",
    "    mismatches = []\n",
    "    for sim in msim.sims:\n",
    "        fit = sim.compute_fit()\n",
    "        mismatches.append(fit.mismatch)\n",
    "    mismatch = np.mean(mismatches)\n",
    "    return mismatch\n",
    "\n",
    "guess = [0.015, 1] # Initial guess of parameters -- beta and relative death probability\n",
    "pars = scipy.optimize.minimize(objective, x0=guess, method='nelder-mead') # Run the optimization\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should converge after roughly 3-10 minutes, although you will likely find that the improvement is minimal.\n",
    "\n",
    "What's happening here? Trying to overcome the limitations of an algorithm that expects deterministic results simply by running more sims is fairly futile – if you run *N* sims and average them together, you've only reduced noise by √*N*, i.e. you have to average together 100 sims to reduce noise by a factor of 10, and even that might not be enough. Clearly, we need a more powerful approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in calibration\n",
    "\n",
    "One such package we have found works reasonably well is called [Optuna](https://optuna.org/). It is built into Covasim as `sim.calibrate()` (it's not installed by default, so please install it first with `pip install optuna`). Do not expect this to be a magic bullet solution: you will likely still need to try out multiple different parameter sets for calibration, manually update the values of uncalibrated parameters, check if the data actually make sense, etc. Even once all these things are in place, it still needs to be run for enough iterations, which might be a few hundred iterations for 3-4 calibrated (free) parameters or tens of thousands of iterations for 10 or more free parameters. The example below should get you started, but best to expect that it will _not_ work for your particular use case without significant modification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example for running built-in calibration with Optuna\n",
    "'''\n",
    "\n",
    "import sciris as sc\n",
    "import covasim as cv\n",
    "\n",
    "# Create default simulation\n",
    "pars = sc.objdict(\n",
    "    pop_size       = 10_000,\n",
    "    start_day      = '2020-02-01',\n",
    "    end_day        = '2020-04-11',\n",
    "    beta           = 0.010,\n",
    "    rel_death_prob = 1.0,\n",
    "    interventions  = cv.test_num(daily_tests='data'),\n",
    "    verbose        = 0,\n",
    ")\n",
    "sim = cv.Sim(pars=pars, datafile='example_data.csv')\n",
    "\n",
    "# Parameters to calibrate -- format is best, low, high\n",
    "calib_pars = dict(\n",
    "    beta           = [pars.beta, 0.005, 0.20],\n",
    "    rel_death_prob = [pars.rel_death_prob, 0.5, 3.0],\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Run the calibration\n",
    "    n_trials = 25\n",
    "    n_workers = 4\n",
    "    calib = sim.calibrate(calib_pars=calib_pars, n_trials=n_trials, n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it improved the fit (see above), but let's visualize this as a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "calib.plot(to_plot=['cum_tests', 'cum_diagnoses', 'cum_deaths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to `scipy.optimize.minimize()`, Optuna took less time and produced a much better fit. However, it's still far from perfect -- more iterations, and calibrating more parameters beyond just these two, would still be required before the model could be considered \"calibrated\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
